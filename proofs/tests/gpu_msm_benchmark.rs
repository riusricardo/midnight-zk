//! GPU MSM Performance Benchmark
//!
//! This benchmark tests dense polynomial commitments where GPU acceleration
//! provides actual speedups. Each test runs twice - first run includes SRS
//! base upload overhead, second run measures actual cached performance.
//!
//! Run with:
//!   cargo test --test gpu_msm_benchmark --features gpu --release -- --ignored --nocapture

#![cfg(feature = "gpu")]

use ff::Field;
use group::{Curve, Group};
use midnight_curves::{Fq as Scalar, G1Affine, G1Projective};
use rand::SeedableRng;
use rand_chacha::ChaCha8Rng;
use std::time::Instant;

use midnight_proofs::gpu::{GpuMsmContext, should_use_gpu, device_type};

/// Benchmark MSM at a given size, comparing GPU vs CPU
/// 
/// Uses the optimized path: upload bases in Montgomery form, use msm_with_device_bases()
/// This is the same path KZG uses for polynomial commitments.
/// 
/// Runs GPU MSM twice:
/// - First run: includes base upload to GPU memory (warmup)
/// - Second run: bases already cached, measures actual MSM performance
/// 
/// Returns: (gpu_warmup_ms, gpu_cached_ms, cpu_ms, speedup)
fn benchmark_msm(size: usize, ctx: &GpuMsmContext) -> (f64, f64, f64, f64) {
    let mut rng = ChaCha8Rng::seed_from_u64(size as u64);
    
    // Generate random scalars and points
    let scalars: Vec<Scalar> = (0..size).map(|_| Scalar::random(&mut rng)).collect();
    let points_proj: Vec<G1Projective> = (0..size)
        .map(|_| G1Projective::random(&mut rng))
        .collect();
    let points: Vec<G1Affine> = points_proj.iter().map(|p| p.to_affine()).collect();
    
    // Optimized path: upload bases in Montgomery form (zero-copy conversion)
    let warmup_start = Instant::now();
    let device_bases = ctx.upload_g1_bases(&points).expect("Failed to upload bases");
    
    // Run 1: First MSM with freshly uploaded bases
    let _ = ctx.msm_with_device_bases(&scalars, &device_bases).expect("GPU MSM failed");
    let gpu_warmup = warmup_start.elapsed().as_secs_f64() * 1000.0;
    
    // Run 2: GPU with cached bases (accurate performance measurement)
    let gpu_start = Instant::now();
    let gpu_result = ctx.msm_with_device_bases(&scalars, &device_bases).expect("GPU MSM failed");
    let gpu_time = gpu_start.elapsed().as_secs_f64() * 1000.0;
    
    // Benchmark CPU MSM (BLST)
    let cpu_start = Instant::now();
    let cpu_result = G1Projective::multi_exp(&points_proj, &scalars);
    let cpu_time = cpu_start.elapsed().as_secs_f64() * 1000.0;
    
    // Verify results match
    assert_eq!(gpu_result, cpu_result, "GPU and CPU results must match!");
    
    let speedup = cpu_time / gpu_time;
    (gpu_warmup, gpu_time, cpu_time, speedup)
}

#[test]
#[ignore]
fn gpu_msm_benchmark() {
    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘  GPU MSM Performance Benchmark - Dense Polynomial Commitments                 â•‘");
    println!("â•‘  Each size runs twice: warmup (includes upload) + cached (accurate timing)    â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();
    
    // Check GPU availability
    println!("Configuration:");
    println!("  â€¢ Device type: {}", device_type());
    println!("  â€¢ GPU threshold: {} points (K â‰¥ {})", 
             midnight_proofs::gpu::min_gpu_size(),
             midnight_proofs::gpu::min_gpu_size().trailing_zeros());
    
    // Initialize GPU context
    print!("  â€¢ Initializing GPU... ");
    let init_start = Instant::now();
    let ctx = GpuMsmContext::new().expect("Failed to create GPU context");
    println!("done in {:?}", init_start.elapsed());
    
    // CUDA context warmup
    print!("  â€¢ CUDA context warmup... ");
    let warmup_start = Instant::now();
    let _ = ctx.warmup();
    println!("done in {:?}", warmup_start.elapsed());
    
    println!();
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();
    
    // Test sizes: K=14-20 representing realistic Midnight circuit sizes
    let test_sizes = vec![
        (14, "16K"),
        (15, "32K"),
        (16, "64K  â† threshold"),
        (17, "128K"),
        (18, "256K"),
        (19, "512K"),
        (20, "1M"),
    ];
    
    println!("â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
    println!("â”‚   K   â”‚  Points  â”‚ Warm (ms)  â”‚ Cache (ms) â”‚  CPU (ms)  â”‚ Speedup  â”‚   Status    â”‚");
    println!("â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");
    
    let mut results = Vec::new();
    
    for (k, label) in test_sizes {
        let size = 1usize << k;
        
        let (gpu_warmup, gpu_cached, cpu_time, speedup) = benchmark_msm(size, &ctx);
        
        let status = if speedup > 1.5 {
            "âœ“ GPU wins"
        } else if speedup > 0.9 {
            "â‰ˆ Similar"
        } else {
            "âœ— CPU wins"
        };
        
        let gpu_better = should_use_gpu(size);
        let threshold_marker = if gpu_better { "â†’" } else { " " };
        
        println!("â”‚{} K={:<2} â”‚ {:>8} â”‚ {:>10.2} â”‚ {:>10.2} â”‚ {:>10.2} â”‚ {:>7.2}x â”‚ {:>11} â”‚",
                 threshold_marker, k, label, gpu_warmup, gpu_cached, cpu_time, speedup, status);
        
        results.push((k, size, gpu_cached, cpu_time, speedup));
    }
    
    println!("â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜");
    println!();
    println!("Legend: â†’ = Above GPU threshold (will use GPU in Auto mode)");
    println!("        Warm = First run (includes SRS upload), Cache = Second run (bases cached)");
    println!();
    
    // Summary
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();
    println!("ğŸ“Š Analysis:");
    
    // Find crossover point
    let crossover = results.iter()
        .find(|(_, _, gpu, cpu, _)| gpu < cpu)
        .map(|(k, _, _, _, _)| *k);
    
    if let Some(k) = crossover {
        println!("  â€¢ GPU becomes faster at K={} ({} points)", k, 1 << k);
    }
    
    // Best speedup
    if let Some((k, _size, _, _, speedup)) = results.iter()
        .max_by(|a, b| a.4.partial_cmp(&b.4).unwrap())
    {
        println!("  â€¢ Best GPU speedup: {:.2}x at K={} ({} points)", speedup, k, 1 << k);
    }
    
    // Largest tested
    if let Some((k, _size, gpu, cpu, speedup)) = results.last() {
        println!("  â€¢ Largest size (K={}): GPU={:.1}ms, CPU={:.1}ms, speedup={:.2}x", 
                 k, gpu, cpu, speedup);
    }
    
    println!();
    println!("ğŸ’¡ Recommendation:");
    println!("  â€¢ Use GPU for MSMs with â‰¥64K points (Kâ‰¥16)");
    println!("  â€¢ Use BLST (CPU) for smaller MSMs due to GPU transfer overhead");
    println!();
}

/// Quick benchmark for CI - tests K=14,15,16,17,18,19 with accurate warmup/cached timing
#[test]
#[ignore]
fn gpu_msm_benchmark_quick() {
    let ctx = GpuMsmContext::new().expect("Failed to create GPU context");
    let _ = ctx.warmup();
    
    println!("\nQuick GPU MSM Benchmark (2nd run = cached, bases in GPU memory):");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("  K  â”‚ Warm (ms) â”‚ Cache (ms) â”‚ CPU (ms) â”‚ Speedup");
    println!("â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    
    for k in [14, 15, 16, 17, 18, 19] {
        let size = 1usize << k;
        let (warmup, cached, cpu, speedup) = benchmark_msm(size, &ctx);
        let marker = if speedup > 1.0 { "âœ“" } else { " " };
        println!(" {:>3} â”‚ {:>9.1} â”‚ {:>10.1} â”‚ {:>8.1} â”‚ {:>5.2}x {}", 
                 k, warmup, cached, cpu, speedup, marker);
    }
    
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("Legend: Warm = includes base upload, Cache = bases already in GPU memory");
}

/// Test that GPU results are correct (using optimized path)
#[test]
fn gpu_msm_correctness() {
    let ctx = GpuMsmContext::new().expect("Failed to create GPU context");
    
    for k in [10, 12, 14, 16] {
        let size = 1usize << k;
        let mut rng = ChaCha8Rng::seed_from_u64(k as u64);
        
        let scalars: Vec<Scalar> = (0..size).map(|_| Scalar::random(&mut rng)).collect();
        let points_proj: Vec<G1Projective> = (0..size)
            .map(|_| G1Projective::random(&mut rng))
            .collect();
        let points: Vec<G1Affine> = points_proj.iter().map(|p| p.to_affine()).collect();
        
        // Test optimized path: upload bases then run MSM
        let device_bases = ctx.upload_g1_bases(&points).expect("Failed to upload bases");
        let gpu_result = ctx.msm_with_device_bases(&scalars, &device_bases).expect("GPU MSM failed");
        let cpu_result = G1Projective::multi_exp(&points_proj, &scalars);
        
        assert_eq!(gpu_result, cpu_result, "GPU/CPU mismatch at K={}", k);
    }
    
    println!("âœ“ GPU MSM correctness verified for K=10,12,14,16");
}

/// Profiling test - runs a single MSM at K specified by PROFILE_K env var
/// Uses the optimized path (upload_g1_bases + msm_with_device_bases)
/// Use with: PROFILE_K=16 ncu --set full ./target/release/deps/gpu_msm_benchmark-* profile_msm_single
#[test]
#[ignore]
fn profile_msm_single() {
    let k: usize = std::env::var("PROFILE_K")
        .unwrap_or_else(|_| "16".to_string())
        .parse()
        .expect("PROFILE_K must be a number");
    
    let size = 1usize << k;
    println!("Profiling MSM at K={} ({} points) using optimized path", k, size);
    
    let mut rng = ChaCha8Rng::seed_from_u64(k as u64);
    
    let scalars: Vec<Scalar> = (0..size).map(|_| Scalar::random(&mut rng)).collect();
    let points_proj: Vec<G1Projective> = (0..size)
        .map(|_| G1Projective::random(&mut rng))
        .collect();
    let points: Vec<G1Affine> = points_proj.iter().map(|p| p.to_affine()).collect();
    
    let ctx = GpuMsmContext::new().expect("Failed to create GPU context");
    let _ = ctx.warmup();
    
    // Upload bases in Montgomery form (zero-copy)
    println!("Uploading bases to GPU (Montgomery form)...");
    let upload_start = Instant::now();
    let device_bases = ctx.upload_g1_bases(&points).expect("Failed to upload bases");
    println!("Bases uploaded in {:?}", upload_start.elapsed());
    
    // Warmup run (cached bases)
    println!("Warmup run...");
    let _ = ctx.msm_with_device_bases(&scalars, &device_bases).expect("GPU MSM failed");
    
    // Profiled run (cached bases, warmed up)
    println!("Profiled run (bases cached, kernel warmed up)...");
    let start = Instant::now();
    let result = ctx.msm_with_device_bases(&scalars, &device_bases).expect("GPU MSM failed");
    let elapsed = start.elapsed();
    
    println!("MSM completed in {:?}", elapsed);
    println!("Result (first bytes): {:?}", &format!("{:?}", result)[..80]);
}
